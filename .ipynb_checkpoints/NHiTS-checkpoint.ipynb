{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a926289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.auto import AutoNHITS\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from ray import tune\n",
    "from utilsforecast.losses import mae, mse\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.INFO)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac0720",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92c8862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df_hist, df_hat, levels=None, model_name=None):\n",
    "    \"\"\"\n",
    "    Plot historical data and forecasts with optional prediction intervals.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_hist : DataFrame\n",
    "        Historical data with columns 'ds' and 'y'\n",
    "    df_hat : DataFrame\n",
    "        Forecast data with columns 'ds', 'unique_id', model predictions, and optional prediction intervals\n",
    "    levels : list of int, optional\n",
    "        Confidence levels for prediction intervals (e.g., [80, 90])\n",
    "    \"\"\"\n",
    "    dash_styles = [\"solid\", \"dot\", \"dash\", \"longdash\", \"dashdot\", \"longdashdot\"]\n",
    "\n",
    "    # Extract base model names (without -lo-XX or -hi-XX suffixes)\n",
    "    models = []\n",
    "    for col in df_hat.columns:\n",
    "        if col in [\"ds\", \"unique_id\"]:\n",
    "            continue\n",
    "        # Check if it's a base model (not a level column)\n",
    "        if not any(\n",
    "            col.endswith(f\"-lo-{level}\") or col.endswith(f\"-hi-{level}\")\n",
    "            for level in levels or []\n",
    "        ):\n",
    "            models.append(col)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add historical data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_hist[\"ds\"],\n",
    "            y=df_hist[\"y\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Historical\",\n",
    "            line=dict(color=\"black\", width=2),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add forecasts and prediction intervals\n",
    "    colors = [\"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\"]\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Add main forecast line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_hat[\"ds\"],\n",
    "                y=df_hat[model],\n",
    "                mode=\"lines\",\n",
    "                name=model,\n",
    "                line=dict(dash=dash_styles[i % len(dash_styles)], color=color, width=2),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add prediction intervals if levels are provided\n",
    "        if levels:\n",
    "            for level in sorted(levels, reverse=True):  # Plot wider intervals first\n",
    "                lo_col = f\"{model}-lo-{level}\"\n",
    "                hi_col = f\"{model}-hi-{level}\"\n",
    "\n",
    "                if lo_col in df_hat.columns and hi_col in df_hat.columns:\n",
    "                    # Add upper bound (invisible line, just for fill)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df_hat[\"ds\"],\n",
    "                            y=df_hat[hi_col],\n",
    "                            mode=\"lines\",\n",
    "                            line=dict(width=0),\n",
    "                            showlegend=False,\n",
    "                            hoverinfo=\"skip\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # Add lower bound with fill\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df_hat[\"ds\"],\n",
    "                            y=df_hat[lo_col],\n",
    "                            mode=\"lines\",\n",
    "                            line=dict(width=0),\n",
    "                            fillcolor=f\"rgba({int(color == 'blue') * 0},{int(color == 'red') * 255},{int(color == 'green') * 0},0.{100 - level // 2})\",\n",
    "                            fill=\"tonexty\",\n",
    "                            name=f\"{model} {level}% PI\",\n",
    "                            hoverinfo=\"skip\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Germany Historical vs Forecast\",\n",
    "        width=1400,\n",
    "        height=500,\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Value\",\n",
    "        hovermode=\"x unified\",\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92542914",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395717a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.read_csv(\n",
    "    \"/mnt/data/oe215/rhindrikson/datasets/load/entsoe/data.csv\", parse_dates=[\"ds\"]\n",
    ")\n",
    "futr_df = pd.read_csv(\n",
    "    \"/mnt/data/oe215/rhindrikson/datasets/load/entsoe/futr.csv\", parse_dates=[\"ds\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98fa9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30644\n",
      "6128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>week_day</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>day_before_holiday</th>\n",
       "      <th>day_after_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>41535.765</td>\n",
       "      <td>load</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>40480.905</td>\n",
       "      <td>load</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  ds          y unique_id  week_day  is_holiday  \\\n",
       "0           0 2022-01-01 00:00:00  41535.765      load         5           1   \n",
       "1           1 2022-01-01 01:00:00  40480.905      load         5           1   \n",
       "\n",
       "   day_before_holiday  day_after_holiday  \n",
       "0                   0                  0  \n",
       "1                   0                  0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define validation and test size\n",
    "n_time = len(Y_df.ds.unique())\n",
    "val_size = int(0.2 * n_time)\n",
    "test_size = int(0.2 * n_time)\n",
    "print(n_time)\n",
    "print(val_size)\n",
    "Y_df.groupby(\"unique_id\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We are going to plot the temperature of the transformer\n",
    "# and marking the validation and train splits\n",
    "u_id = \"load\"\n",
    "x_plot = pd.to_datetime(Y_df[Y_df.unique_id == u_id].ds)\n",
    "y_plot = Y_df[Y_df.unique_id == u_id].y.values\n",
    "\n",
    "x_val = x_plot[n_time - val_size - test_size]\n",
    "x_test = x_plot[n_time - test_size]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.xlabel(\"Date\", fontsize=17)\n",
    "plt.ylabel(\"Load [Hourly temperature]\", fontsize=17)\n",
    "\n",
    "plt.axvline(x_val, color=\"black\", linestyle=\"-.\")\n",
    "plt.axvline(x_test, color=\"black\", linestyle=\"-.\")\n",
    "plt.text(x_val, 5, \"  Validation\", fontsize=12)\n",
    "plt.text(x_test, 5, \"  Test\", fontsize=12)\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72b9cf",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7 * 24\n",
    "\n",
    "nhits_config = {\n",
    "    \"learning_rate\": tune.choice([1e-3]),  # Initial Learning rate\n",
    "    \"max_steps\": tune.choice([1000]),  # Number of SGD steps\n",
    "    \"input_size\": tune.choice([104 * horizon]),  # input_size = multiplier * horizon\n",
    "    \"batch_size\": tune.choice([7]),  # Number of series in windows\n",
    "    \"windows_batch_size\": tune.choice([256]),  # Number of windows in batch\n",
    "    \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),  # MaxPool's Kernelsize\n",
    "    \"n_freq_downsample\": tune.choice(\n",
    "        [[168, 24, 1], [24, 12, 1], [1, 1, 1]]\n",
    "    ),  # Interpolation expressivity ratios\n",
    "    \"activation\": tune.choice([\"ReLU\"]),  # Type of non-linear activation\n",
    "    \"n_blocks\": tune.choice([[1, 1, 1]]),  # Blocks per each 3 stacks\n",
    "    \"mlp_units\": tune.choice(\n",
    "        [[[512, 512], [512, 512], [512, 512]]]\n",
    "    ),  # 2 512-Layers per block for each stack\n",
    "    \"interpolation_mode\": tune.choice([\"linear\"]),  # Type of multi-step interpolation\n",
    "    \"val_check_steps\": tune.choice([100]),  # Compute validation every 100 epochs\n",
    "    \"random_seed\": tune.randint(1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822cf56c",
   "metadata": {},
   "source": [
    "## Instantiate Model\n",
    "\n",
    "To instantiate `AutoNHITS` you need to define:\n",
    "\n",
    "* `h`: forecasting horizon\n",
    "* `loss`: training loss. Use the `DistributionLoss` to produce probabilistic forecasts.\n",
    "* `config`: hyperparameter search space. If `None`, the `AutoNHITS` class will use a pre-defined suggested hyperparameter space.\n",
    "* `num_samples`: number of configurations explored.\n",
    "\n",
    "If num_samples equals 5, the AutoNHITS model will randomly sample 5 different combinations of hyperparameters from the search space defined in nhits_config.\n",
    "Each configuration will be trained and evaluated.\n",
    "The best performing configuration (based on validation performance) will be selected as the final model\n",
    "\n",
    "For loss, common distribution options include:\n",
    "- 'Normal' or 'Gaussian' - for normal/gaussian distribution\n",
    "- 'StudentT' or 'T' - for Student's t-distribution\n",
    "- 'NegativeBinomial' - for count data\n",
    "- 'Poisson' - for count data\n",
    "- 'Tweedie' - for non-negative continuous data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [80, 90]\n",
    "# loss=MQLoss(level=levels),\n",
    "loss = DistributionLoss(distribution=\"Normal\", level=levels)\n",
    "models = [\n",
    "    AutoNHITS(\n",
    "        h=horizon,\n",
    "        loss=loss,\n",
    "        config=nhits_config,\n",
    "        num_samples=5,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f59381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nf = NeuralForecast(models=models, freq=\"h\")\n",
    "\n",
    "Y_hat_df = nf.cross_validation(\n",
    "    df=Y_df, val_size=val_size, test_size=test_size, n_windows=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66076c59",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "\n",
    "The `AutoNHITS` class contains a `results` tune attribute that stores information of each configuration explored. It contains the validation loss and best validation hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.models[0].results.get_best_result().config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_hat_df.y.values\n",
    "y_hat = Y_hat_df[\"AutoNHITS\"].values\n",
    "\n",
    "n_series = len(Y_df.unique_id.unique())\n",
    "\n",
    "y_true = y_true.reshape(n_series, -1, horizon)\n",
    "y_hat = y_hat.reshape(n_series, -1, horizon)\n",
    "\n",
    "print(\"Parsed results\")\n",
    "print(\"2. y_true.shape (n_series, n_windows, n_time_out):\\t\", y_true.shape)\n",
    "print(\"2. y_hat.shape  (n_series, n_windows, n_time_out):\\t\", y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(10, 11))\n",
    "fig.tight_layout()\n",
    "\n",
    "series = [\"load\"]\n",
    "series_idx = 0\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_true[series_idx, :, :].flatten(), label=\"True\")\n",
    "plt.plot(y_hat[series_idx, :, :].flatten(), label=\"Forecast\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Time\", fontsize=14)\n",
    "plt.ylabel(series[series_idx], fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fb971",
   "metadata": {},
   "source": [
    "Finally, we compute the test errors for the two metrics of interest:\n",
    "\n",
    "$\\qquad MAE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}| \\qquad$ and $\\qquad MSE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\qquad$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.losses.numpy import mae, mse\n",
    "\n",
    "print(\"MAE: \", mae(y_hat, y_true))\n",
    "print(\"MSE: \", mse(y_hat, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc455370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tms",
   "language": "python",
   "name": "tms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
